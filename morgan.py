"""
Morgan - Main Orchestrator & Todo Generator

Central coordination of all components for smart Slack todo management.
"""

import asyncio
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional

from models import (
    SlackMessage, AIAnalysis, PriorityScore, TodoItem, TodoList, 
    Priority, UserPattern, LearningFeedback
)
from slack_client import SlackClient
from ai_engine import AIEngine
from priority_engine import PriorityCalculator


class TodoGenerator:
    """Generates smart todo items from analyzed Slack activities"""
    
    def __init__(self):
        pass
    
    def generate_todo_item(self, message: SlackMessage, analysis: AIAnalysis, 
                          priority_score: PriorityScore) -> TodoItem:
        """Generate a single todo item"""
        
        # Generate title
        title = self._generate_title(message, analysis)
        
        # Generate description
        description = self._generate_description(message, analysis, priority_score)
        
        # Generate tags
        tags = self._generate_tags(message, analysis)
        
        return TodoItem(
            id=str(uuid.uuid4()),
            source_message=message,
            ai_analysis=analysis,
            priority_score=priority_score,
            title=title,
            description=description,
            tags=tags
        )
    
    def _generate_title(self, message: SlackMessage, analysis: AIAnalysis) -> str:
        """Generate concise todo title"""
        sender = message.username
        
        # Extract action from message
        text = message.text.strip()
        
        # Common patterns for todo titles
        if "?" in text:
            # Question -> "ë‹µë³€: ..."
            return f"ë‹µë³€: {sender}ì˜ ì§ˆë¬¸"
        elif any(word in text.lower() for word in ["review", "ê²€í† "]):
            return f"ê²€í† : {sender} ìš”ì²­"
        elif any(word in text.lower() for word in ["meeting", "íšŒì˜"]):
            return f"íšŒì˜: {sender}ì™€ ë…¼ì˜"
        elif any(word in text.lower() for word in ["approve", "ìŠ¹ì¸"]):
            return f"ìŠ¹ì¸: {sender} ìš”ì²­ ê±´"
        elif analysis.work_type.value == "decision":
            return f"ê²°ì •: {sender} ì˜ì‚¬ê²°ì • í•„ìš”"
        elif analysis.work_type.value == "support":
            return f"ì§€ì›: {sender} ë„ì›€ ìš”ì²­"
        else:
            # Generic title
            return f"ì²˜ë¦¬: {sender}ì˜ ë©”ì‹œì§€"
    
    def _generate_description(self, message: SlackMessage, analysis: AIAnalysis, 
                            priority_score: PriorityScore) -> str:
        """Generate detailed todo description"""
        lines = []
        
        # Message preview
        preview = message.text[:100] + "..." if len(message.text) > 100 else message.text
        lines.append(f"ğŸ’¬ \"{preview}\"")
        lines.append("")
        
        # Context info
        lines.append(f"ğŸ‘¤ ë°œì‹ ì: {message.username}")
        lines.append(f"ğŸ“ ì±„ë„: #{message.channel_name} ({message.activity_type})")
        lines.append(f"â° ì‹œê°„: {message.timestamp.strftime('%Y-%m-%d %H:%M')}")
        lines.append("")
        
        # AI Analysis
        lines.append(f"ğŸ¤– AI ë¶„ì„:")
        lines.append(f"  - ì‘ì—… ìœ í˜•: {analysis.work_type}")
        lines.append(f"  - ë³µì¡ë„: {analysis.complexity}")
        lines.append(f"  - ì˜ˆìƒ ì†Œìš”ì‹œê°„: {analysis.estimated_time_minutes}ë¶„")
        lines.append(f"  - ê°ì •ì  í†¤: {analysis.emotional_tone}")
        if analysis.detected_keywords:
            lines.append(f"  - í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(analysis.detected_keywords)}")
        lines.append("")
        
        # Priority reasoning
        lines.append(f"ğŸ¯ ìš°ì„ ìˆœìœ„ ê·¼ê±°: {priority_score.reasoning}")
        lines.append(f"ğŸ“… ê¶Œì¥ ì²˜ë¦¬ì‹œê°„: {priority_score.recommended_action_time}")
        
        return "\n".join(lines)
    
    def _generate_tags(self, message: SlackMessage, analysis: AIAnalysis) -> List[str]:
        """Generate relevant tags"""
        tags = []
        
        # Activity type tag
        tags.append(f"type:{message.activity_type}")
        
        # Work type tag
        tags.append(f"work:{analysis.work_type}")
        
        # Channel tag
        tags.append(f"channel:{message.channel_name}")
        
        # Urgency tag
        if analysis.urgency_score > 0.8:
            tags.append("urgent")
        elif analysis.urgency_score > 0.6:
            tags.append("important")
        
        # Complexity tag
        tags.append(f"complexity:{analysis.complexity}")
        
        # Time estimate tag
        if analysis.estimated_time_minutes <= 15:
            tags.append("quick")
        elif analysis.estimated_time_minutes >= 60:
            tags.append("deep-work")
        
        return tags
    
    def generate_todo_list(self, analyzed_messages: List[tuple[SlackMessage, AIAnalysis, PriorityScore]],
                          title: str = None) -> TodoList:
        """Generate complete todo list from analyzed messages"""
        
        # Generate todos
        todos = []
        models_used = set()
        
        for message, analysis, priority in analyzed_messages:
            if analysis.action_required:  # Only create todos for actionable items
                todo = self.generate_todo_item(message, analysis, priority)
                todos.append(todo)
                models_used.add(analysis.model_used)
        
        # Sort by priority score (highest first)
        todos.sort(key=lambda t: t.priority_score.final_score, reverse=True)
        
        # Generate list metadata
        if not title:
            title = f"ìŠ¤ë§ˆíŠ¸ í• ì¼ ëª©ë¡ - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        
        todo_list = TodoList(
            id=str(uuid.uuid4()),
            title=title,
            description=f"{len(analyzed_messages)}ê°œ ë©”ì‹œì§€ ë¶„ì„ ê²°ê³¼",
            items=todos,
            total_items=len(todos),
            completed_items=0,
            ai_models_used=list(models_used)
        )
        
        return todo_list


class MorganOrchestrator:
    """Main orchestrator that coordinates all components"""
    
    def __init__(self):
        self.slack_client = SlackClient()
        self.ai_engine = AIEngine()
        self.priority_calculator = PriorityCalculator()
        self.todo_generator = TodoGenerator()
        
        # User patterns for learning (would be loaded from database)
        self.user_patterns: List[UserPattern] = []
    
    async def process_slack_activities(self, hours: int = 24, 
                                      max_messages: int = 100) -> TodoList:
        """Main processing pipeline"""
        print("ğŸš€ Morganì´ ìŠ¬ë™ í™œë™ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        try:
            # Step 1: Collect Slack activities
            print("\nğŸ“± 1ë‹¨ê³„: Slack í™œë™ ìˆ˜ì§‘")
            activities = await self.slack_client.collect_all_activities(hours)
            
            if not activities:
                print("âŒ ìŠ¬ë™ í™œë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return TodoList(
                    id=str(uuid.uuid4()),
                    title="ë¹ˆ í• ì¼ ëª©ë¡",
                    description="ë¶„ì„í•  í™œë™ì´ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # Limit number of messages to process
            if len(activities) > max_messages:
                print(f"âš ï¸ ë©”ì‹œì§€ê°€ ë§ì•„ ìµœê·¼ {max_messages}ê°œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                activities = activities[:max_messages]
            
            # Step 2: AI Analysis
            print(f"\nğŸ¤– 2ë‹¨ê³„: AI ë¶„ì„ ({len(activities)}ê°œ ë©”ì‹œì§€)")
            analyzed_activities = await self.ai_engine.analyze_batch(activities)
            
            # Step 3: Priority Calculation
            print(f"\nğŸ¯ 3ë‹¨ê³„: ìš°ì„ ìˆœìœ„ ê³„ì‚°")
            prioritized_activities = []
            for message, analysis in analyzed_activities:
                priority = self.priority_calculator.calculate_priority(
                    message, analysis, self.user_patterns
                )
                prioritized_activities.append((message, analysis, priority))
            
            # Step 4: Todo Generation
            print(f"\nğŸ“‹ 4ë‹¨ê³„: í• ì¼ ëª©ë¡ ìƒì„±")
            todo_list = self.todo_generator.generate_todo_list(prioritized_activities)
            
            # Step 5: Summary
            print(f"\nâœ… ì™„ë£Œ!")
            print(f"  - ë¶„ì„ëœ ë©”ì‹œì§€: {len(activities)}ê°œ")
            print(f"  - ìƒì„±ëœ í• ì¼: {len(todo_list.items)}ê°œ")
            print(f"  - ì‚¬ìš©ëœ AI ëª¨ë¸: {', '.join(todo_list.ai_models_used)}")
            
            # Usage stats
            stats = self.ai_engine.get_usage_stats()
            print(f"  - AI í˜¸ì¶œ: OpenAI {stats['openai_calls']}íšŒ, Claude {stats['claude_calls']}íšŒ")
            print(f"  - ì˜ˆìƒ ë¹„ìš©: ${stats['estimated_cost_usd']}")
            
            return todo_list
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
            # Return empty todo list
            return TodoList(
                id=str(uuid.uuid4()),
                title="ì˜¤ë¥˜ - ë¹ˆ í• ì¼ ëª©ë¡",
                description=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            )
    
    def collect_feedback(self, todo_id: str, satisfaction: int, 
                        feedback_text: str = None, actual_priority: Priority = None) -> LearningFeedback:
        """Collect user feedback for learning"""
        # Find the todo item (in real implementation, this would query database)
        # For now, create feedback object
        
        feedback = LearningFeedback(
            todo_id=todo_id,
            predicted_priority=Priority.MEDIUM,  # Would get from actual todo
            actual_priority=actual_priority,
            user_satisfaction=satisfaction,
            feedback_text=feedback_text
        )
        
        print(f"ğŸ“ í”¼ë“œë°± ìˆ˜ì§‘ë¨: ë§Œì¡±ë„ {satisfaction}/5")
        if feedback_text:
            print(f"   ì˜ê²¬: {feedback_text}")
        
        # TODO: Store in database and update learning patterns
        
        return feedback
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """Get summary statistics"""
        ai_stats = self.ai_engine.get_usage_stats()
        
        return {
            "ai_usage": ai_stats,
            "user_patterns_count": len(self.user_patterns),
            "last_processed": datetime.now().isoformat()
        }


# Test Morgan orchestrator
if __name__ == "__main__":
    async def test_morgan():
        morgan = MorganOrchestrator()
        
        print("ğŸ§ª Testing Morgan orchestrator...")
        print("Note: This requires valid Slack and AI API tokens in environment variables.")
        
        # Test with limited scope
        todo_list = await morgan.process_slack_activities(hours=1, max_messages=5)
        
        if todo_list.items:
            print(f"\nğŸ“‹ Generated {len(todo_list.items)} todos:")
            for i, todo in enumerate(todo_list.items[:3]):
                print(f"{i+1}. [{todo.priority}] {todo.title}")
                print(f"   {todo.source_message.username}: {todo.source_message.text[:50]}...")
                print()
        else:
            print("No todos generated (no actionable messages found)")
        
        # Test feedback collection
        if todo_list.items:
            feedback = morgan.collect_feedback(
                todo_id=todo_list.items[0].id,
                satisfaction=4,
                feedback_text="ìš°ì„ ìˆœìœ„ê°€ ì ì ˆí–ˆìŠµë‹ˆë‹¤"
            )
            print(f"Feedback collected: {feedback.user_satisfaction}/5")
    
    # Uncomment to test (requires API keys)
    # asyncio.run(test_morgan())